[{"id":0,"title":"Runtime API Examples","content":"#\n\nThis page demonstrates usage of some of the runtime APIs provided by VitePress.\n\nThe main useData() API can be used to access site, theme, and page data for the\ncurrent page. It works in both .md and .vue files:\n\n\n\n\nResults#\n\n\nTheme Data#\n\n\nPage Data#\n\n\nPage Frontmatter#\n\n\nMore#\n\nCheck out the documentation for the full list of runtime APIs.","routePath":"/api-examples","lang":"","toc":[{"text":"Results","id":"results","depth":2,"charIndex":218},{"text":"Theme Data","id":"theme-data","depth":3,"charIndex":229},{"text":"Page Data","id":"page-data","depth":3,"charIndex":243},{"text":"Page Frontmatter","id":"page-frontmatter","depth":3,"charIndex":256},{"text":"More","id":"more","depth":2,"charIndex":276}],"domain":"","frontmatter":{"outline":"deep"},"version":""},{"id":1,"title":"awesome","content":"#\n\n\n服务端#\n\n * Skia Canvas: 服务端Canvas绘图(Github)","routePath":"/awesome","lang":"","toc":[{"text":"服务端","id":"服务端","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":2,"title":"hadoop","content":"#\n\n\n环境#\n\n\n初始化#\n\n1. 启动三台服务器#\n\n准备 3 台虚拟机，2CPU 4G 50G. hadoop001 hadoop002 hadoop003\n\nmultipass 的方式启动对应三台\n\n\n\n设置对应服务器名(multipass已有，不用再处理)\n\nvim /etc/hostname\n\n2. 配置清华源#\n\n参考：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 修改配置后\n\n\n\n3. 基本环境处理#\n\n安装 net-tools\n\nsudo apt install net-tools\n\n确保可以 ping 通外网\n\n关闭且禁用防火墙\n\nsudo ufw disable\n\nsudo ufw status 当显示 Status: inactive 则为关闭且禁用的状态\n\n添加 hosts\n\nvim /etc/hosts\n\n\n\n创建用户\n\n> 使用multipass，直接用默认ubuntu用户，可以忽略以下步骤\n\nroot 下创建 shadoop 用户，且设置密码 shadoop useradd shadoop passwd shadoop\n\n配置 shadoop 用户 root 权限，方便需要 sudo 的命令vim /etc/sudoers添加shadoop ALL=(ALL)\nNOPASSWD:ALL\n\n创建目录 /opt/module /opt/software\n\n创建两个文件夹mkdir /opt/module,mkdir /opt/software\n\n修改用户组chown shadoop:shadoop /opt/module,chown shadoop:shadoop /opt/software\n\n\n\n查看ll\n\n配置ssh\n\n配置 hadoop001,hadoop002,hadoop003 的 ubuntu 用户相互 ssh 免密访问\n\n配置 hadoop001 的 root 用户到hadoop002,hadoop003 的 ssh 免密访问\n\n生成 sshssh-keygen -t rsa\n\n4. 安装jdk#\n\n安装 openjdksudo apt install openjdk-8-jdk\n\n安装 openjdk 后配置 JAVA_HOME 变量到 shell\n\n\n\n4. 安装hadoop#\n\n下载hadoop-3.1.3.tar.gz 到/opt/software hadoop001\n\n下载慢的话，下载到宿主机，scp 到 hadoop001 scp hadoop-3.1.3.tar.gz\nubuntu@hadoop001:/opt/software\n\n解压tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/\n\n将 hadoop 添加到环境变量\n\nsudo vim /etc/profile.d/my_env.sh\n\n\n\nsource /etc/profile\n\n验证 hadoop version\n\n> 如果出现ERROR: JAVA_HOME is not set and could not be found.\n\n正确显示\n\n\n\n5. 集群分发脚本xsync#\n\n需要对应用户名ssh可通\n\nscp (secure copy) 实现服务器间copy数据\n\n\n\nrsync 用于备份和镜像，相较于scp，scp是复制所以文件，rsync复制差异文件\n\n\n\n如将hadoop复制到hadoop002rsync -av hadoop-3.1.3/\nshadoop@hadoop002:/opt/module/hadoop-3.1.3/\n\n编写脚本，${HOME}/bin目录下vim xsync\n\n\n\n修改执行权限chmod +x xsync\n\n测试脚本 ./xsync /home/shadoop/bin/\n\n将脚本复制到/bin/中，方便全局调用sudo cp xsync /bin/\n\n前面已复制hadoop到其他服务器中，若没复制xsync /opt/module/hadoop-3.1.3\n\n复制配置到其他服务器sudo /bin/xsync /etc/profile.d/my_env.sh\n\n去其他服务器中，使配置生效source /etc/profile.d/my_env.sh\n\n保证所有服务器都有hadoop环境\n\n\n集群#\n\n集群规划#\n\n       HADOOP001          HADOOP002                    HADOOP003\nHDFS   NameNodeDataNode   DataNode                     SecondaryNameNodeDataNode\nYARN   NodeManager        ResourceManagerNodeManager   NodeManager\n\n>  * NameNode 和 SecondaryNameNode 不要安装在同一台服务器\n>  * ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode 配置在 同一台机器上。\n\n配置集群#\n\n配置文件目录$HADOOP_HOME/etc/hadoop\n\ncore-site.xml\n\n\n\nhdfs-site.xml\n\n\n\nyarn-site.xml\n\n\n\nmapred-site.xml\n\n\n\n分发配置 xsync /opt/module/hadoop-3.1.3/etc/hadoop/\n\n配置群起worksvim workers\n\n\n\n分发配置 xsync /opt/module/hadoop-3.1.3/etc/","routePath":"/blog/2024-08-23-hadoop","lang":"","toc":[{"text":"环境","id":"环境","depth":2,"charIndex":3},{"text":"初始化","id":"初始化","depth":3,"charIndex":9},{"text":"1. 启动三台服务器","id":"1-启动三台服务器","depth":4,"charIndex":15},{"text":"2. 配置清华源","id":"2-配置清华源","depth":4,"charIndex":153},{"text":"3. 基本环境处理","id":"3-基本环境处理","depth":4,"charIndex":226},{"text":"4. 安装jdk","id":"4-安装jdk","depth":4,"charIndex":901},{"text":"4. 安装hadoop","id":"4-安装hadoop","depth":4,"charIndex":992},{"text":"5. 集群分发脚本xsync","id":"5-集群分发脚本xsync","depth":4,"charIndex":1350},{"text":"集群","id":"集群","depth":3,"charIndex":1851},{"text":"集群规划","id":"集群规划","depth":4,"charIndex":1856},{"text":"配置集群","id":"配置集群","depth":4,"charIndex":2195}],"domain":"","frontmatter":{},"version":""},{"id":3,"title":"本地部署deepseek","content":"#\n\n\n1. 下载安装ollama#\n\n参考：https://ollama.com/\n\nTIP\n\nwindows下，最好使用WSL安装\n\n\n2. 下载运行DeepSeek-R1#\n\n搜索 deepseek-r1 ，参考：https://ollama.com/library/deepseek-r1:8b\n\n\n\n\n3. 下载open-webui#\n\n参考：https://github.com/open-webui/open-webui\n\n这里本机运行的ollama，可以使用：\n\n\n\n\n4. 运行#\n\n> [!IMPORTANT]\n> \n> 先ollama运行LLM，再启动open-webui","routePath":"/blog/2025-02-05-本地部署deepseek","lang":"","toc":[{"text":"1. 下载安装ollama","id":"1-下载安装ollama","depth":2,"charIndex":3},{"text":"2. 下载运行DeepSeek-R1","id":"2-下载运行deepseek-r1","depth":2,"charIndex":69},{"text":"3. 下载open-webui","id":"3-下载open-webui","depth":2,"charIndex":155},{"text":"4. 运行","id":"4-运行","depth":2,"charIndex":242}],"domain":"","frontmatter":{"date":"2025-02-05T15:36:04.000Z"},"version":""},{"id":4,"title":"daily","content":"#\n\n\n2025-07-21#\n\nrust中Cow，eg: pub tags: HashMap<Cow<'static, str>, Cow<'static, str>>,\n\n\n2025-07-17#\n\nliterals\n\ninference\n\nconversion\n\n\n2025-07-14#\n\nidentity reusable compression","routePath":"/daily/","lang":"","toc":[{"text":"2025-07-21","id":"2025-07-21","depth":3,"charIndex":3},{"text":"2025-07-17","id":"2025-07-17","depth":3,"charIndex":88},{"text":"2025-07-14","id":"2025-07-14","depth":2,"charIndex":135}],"domain":"","frontmatter":{},"version":""},{"id":5,"title":"JWT","content":"#\n\nJson Web Token。\n\n参考https://datatracker.ietf.org/doc/html/rfc7519\n\n\nJWT的组成#\n\n\n\n由header.payload.signature组成\n\n\nheader#\n\nheader其实是JOSE Header（Joint Object Signing and Encryption Header）。是JSON Web\nSignature (JWS) 和 JSON Web Encryption (JWE) 中的一个重要组成部分。它位于 JWT（JSON Web\nToken）的头部，并且通常用于携带与签名或加密相关的元数据。\n\n标准参数#\n\nKEY   NAME        \nalg   Algorithm   指定了签名或加密算法。\ntyp   Type        指示了对象类型，通常是 JWT。\n...   ...         其他可以不太用管\n\n通常如:\n\n\n\n\npayload#\n\npayload也就是JWT Claims。分为三种:\n\n * Registered Claim Names: 保留的claim。\n * Public Claim Names: 公共的信息。一般携带的信息放在这。\n * Private Claim Names: 私有的声明。生产者和消费者都同意使用的声明。\n\nRegistered Claim Names保留的信息：\n\n * iss:\n * sub:\n * and:\n * exp:\n * nbf:\n * iat:\n * jti:","routePath":"/document/JWT","lang":"","toc":[{"text":"JWT的组成","id":"jwt的组成","depth":2,"charIndex":69},{"text":"header","id":"header","depth":3,"charIndex":110},{"text":"标准参数","id":"标准参数","depth":4,"charIndex":299},{"text":"payload","id":"payload","depth":2,"charIndex":427}],"domain":"","frontmatter":{},"version":""},{"id":6,"title":"Database 数据库","content":"#\n\n\nTime Series Database (TSDB) 时序数据库#\n\n时序数据库（Time Series Database,\nTSDB）是一种专用数据库管理系统，设计用于高效存储、检索和分析按时间顺序排列的数据点，即时间序列数据。这类数据库主要用于处理和管理随着时间推移不断变化的数据，\n如传感器读数、服务器监控指标、金融市场的交易数据、应用性能指标等。\n\n时序数据的特点通常包括：\n\n 1. 时间戳：每个数据点都有一个明确的时间戳，表示数据被测量或生成的具体时刻。\n 2. 连续数据流：数据按照时间顺序持续流入数据库。\n 3. 高写入吞吐量：因为时序数据往往由大量源头快速生成，数据库需要能够处理高频率的写入操作。\n 4. 大量的数据点：时序数据库经常要处理从数千到数十亿个数据点的情况，且数据规模随着时间增长。\n 5. 查询模式特定：查询通常涉及时间范围内的聚合（如平均值、最大值、最小值）、趋势分析和异常检测。\n\n时序数据库通过优化存储结构、索引机制和查询算法来满足这些特点带来的挑战，从而在大规模时间序列数据的场景下提供更佳的性能表现。相比于通用的关系型数据库或非关系型数\n据库，时序数据库更适合进行实时监控、历史数据分析以及未来预测等工作。\n\n\n什么情况下需要时序数据库#\n\n * 抵达的数据几乎总是作为新条目被记录\n\n * 数据通常按照时间顺序抵达\n\n * 时间是一个主坐标轴（既可以是规则的时间间隔，也可以是不规则的）\n\n\n为什么用时序数据库而不用一般数据库#\n\n * 规模： 时间序列数据累计速度非常快。\n\n * 可用性：TSDB 通常还包括一些共通的对时间序列数据分析的功能和操作：数据保留策略、连续查询、灵活的时间聚合等。\n\n\n似乎跟日志差不多，为什么要专门的时序数据库呢#\n\n虽然时序数据和日志数据在某种程度上有相似之处，即它们都可以包含时间戳并按时间顺序组织，但时序数据的特性和使用场景决定了其对数据库系统的要求与其他类型数据存储有所\n不同。以下是几个关键原因，解释了为何需要专门的时序数据库：\n\n 1. 数据写入频率高：时序数据通常来自于传感器网络、监控系统、物联网设备等，这些系统会产生海量且频繁更新的数据。相较于传统数据库，时序数据库经过优化可以实现非\n    常高的写入吞吐量，能够轻松应对每秒成千上万条数据的写入。\n 2. 数据压缩与存储效率：由于时序数据具有很强的规律性（例如，相邻数据点可能变化不大），时序数据库会采用高效的压缩算法减少存储空间占用，尤其是在长期存储和归档\n    时尤为重要。\n 3. 时间相关的查询优化：时序数据库针对时间序列特有的查询模式进行了优化，例如区间查询（按时间段获取数据）、聚合查询（计算一段时间内数据的平均值、最大值、最小\n    值等统计量）、及多维查询（按标签维度筛选数据）。\n 4. 预计算与缓存：为了提高查询响应速度，时序数据库可以预先计算并存储常用的聚合结果或者利用缓存机制加速查询。\n 5. 时间窗口分析：对于实时分析和告警系统，时序数据库可以很好地支持基于时间窗口的复杂分析，例如滑动窗口统计、滞后窗口比较等。\n 6. 大规模分布式处理：时序数据库通常设计为可横向扩展的架构，能处理PB级甚至EB级的数据量，并确保在大数据量下的稳定性和性能。\n\n因此，尽管日志数据也可以包含时间戳，但它通常侧重于事件记录和事后审计，而时序数据库则专注于高性能、高并发的实时/近实时数据捕获、存储和分析，尤其适用于需要实时监\n控和预测的应用场景。通过专门设计的时序数据库，企业能够更好地管理和利用随时间演变的数据资产，提升业务洞察力和决策效率。\n\n> 参考文档：\n> \n> https://gist.github.com/baymaxium/a3d21bf2dd95ff1fe6d39c870455da47","routePath":"/document/database","lang":"","toc":[{"text":"Time Series Database (TSDB) 时序数据库","id":"time-series-database-tsdb-时序数据库","depth":2,"charIndex":3},{"text":"什么情况下需要时序数据库","id":"什么情况下需要时序数据库","depth":3,"charIndex":532},{"text":"为什么用时序数据库而不用一般数据库","id":"为什么用时序数据库而不用一般数据库","depth":3,"charIndex":623},{"text":"似乎跟日志差不多，为什么要专门的时序数据库呢","id":"似乎跟日志差不多为什么要专门的时序数据库呢","depth":3,"charIndex":728}],"domain":"","frontmatter":{},"version":""},{"id":7,"title":"latest RabbitMQ 4.x","content":"#\n\ndocker volume create rabbitmq-data\n\n","routePath":"/document/docker/docker-rabbitmq","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":8,"title":"Docker Redis","content":"#\n\n\n\n\n\n * -p: 指定容器端口映射到主机端口\n * --name: 指定运行容器名\n\n进入运行的 Redis 服务\n\n\n\n\n单节点部署Redis操作#\n\n 1. 拉取基本配置文件到配置目录\n    \n    从github的redis里获取，比如当前最新版本为7.4，则地址为https://github.com/redis/redis/blob/8.0/re\n    dis.conf\n    \n    拷贝内容，写入/home/docker/redis/config名为redis.conf\n\n 2. 启动 创建数据卷，启动docker\n\n\n\n 3. 修改配置\n    \n    * protected-mode no：可非本host访问\n    \n    * requirepass 123456: 开启密码访问\n    \n    * appendonly yes：启用AOF持久化\n    \n    * aof-use-rdb-preamble yes：开启混合持久化模式（RDB + AOF）\n    \n    * bind 0.0.0.0 -::1：使宿主机可以访问\n      \n      重启redis\n\n注意#\n\n> 问题1：\n> \n> WARNING Memory overcommit must be enabled! Without it, a background save or\n> replication may fail under low memory condition. Being disabled, it can also\n> cause failures without low memory condition, see\n> https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add\n> 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the\n> command 'sysctl vm.overcommit_memory=1' for this to take effect.\n> \n> 解决：sudo vim /etc/sysctl.conf,sudo sysctl -p,sysctl\n> vm.overcommit_memory重启docker的redis\n> \n> 问题2：\n> \n> 启动后docker logs发现报错 Failed to write PID file: Permission denied\n> \n> 解决：使用--privileged启动提升权限","routePath":"/document/docker/docker-redis","lang":"","toc":[{"text":"单节点部署Redis操作","id":"单节点部署redis操作","depth":3,"charIndex":66},{"text":"注意","id":"注意","depth":4,"charIndex":516}],"domain":"","frontmatter":{},"version":""},{"id":9,"title":"Docker 快速部署容器","content":"#\n\n\nDocker 部署 Mysql#\n\n\n\n\n\n * -p: 指定容器端口映射到主机端口\n\n * --name: 指定运行容器名\n\n * -e: 设置环境变量。\n   \n   * MYSQL_ROOT_PASSWORD=123456设置 mysql 服务 root 用户密码 123456\n\n * --restart=always: 当Docker守护进程启动时，这个设置确保即使容器停止，它也会自动重启。\n\n * -v <宿主机文件夹路径，如：/**/mysql>:/var/lib/mysql:\n   将宿主机上的目录/**/mysql映射到容器内的/var/lib/mysql目录。这样可以将数据持久化存储在宿主机上，避免容器重启或销毁时丢失数据。\n\n * -d: 这个标志表示容器应该以后台（守护进程）模式运行，不会阻塞终端。\n\ndocker run -itd --name local-mysql --restart=always -v\n/home/docker/mysql:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456\nmysql\n\n\nDocker 部署 Mongodb#\n\n\n\n\n\n指定版本\n\ndocker pull mongo:4.2.24\n\ndocker run -itd --name mongo-4.2.24 -p 27017:27017 mongo:4.2.24\n\n\n单节点部署mongo#\n\n写入初始mongod.conf（/home/docker/mongo/config/mongod.conf）\n\n\n\n\n\n\nDocker 部署 Minio#\n\ndocker pull minio/minio\n\nlinux\n\n\n\nwindows\n\n\n\n/data：\n\n在MinIO中，/data目录是默认的数据存储位置。这意味着所有的对象数据（上传的文件、桶信息等）都将存储在宿主机的/home/data目录下，而不是在容器内部\n。这种做法的好处是：\n\n * 数据持久化：即使容器被删除或重建，数据仍然保留在宿主机上，不会丢失。\n * 数据独立：数据存储在宿主机上，不依赖于容器的存在，便于数据管理和迁移。\n * 多容器共享：如果多个MinIO容器需要共享相同的数据，可以指向同一个目录。\n\n/root/.minio:\n\n这个映射将宿主机上的/home/config目录映射到容器内的/root/.minio目录。在MinIO中，/root/.minio目录通常用于存储MinIO的\n配置文件和证书等敏感信息。通过映射到宿主机上的目录，你可以：\n\n * 配置持久化：容器内的配置更改可以永久保存在宿主机上，即使容器重启或重建，配置依然存在。\n * 安全性：敏感信息如访问密钥、安全证书等可以安全地存储在宿主机上，而不是在容器内部，减少安全风险。\n * 可管理性：在宿主机上直接编辑配置文件，无需进入容器内部，便于管理和备份。\n\nserver /data --console-address \":9001\": 这是运行MinIO服务器的命令，server\n/data表示使用/data目录作为数据存储路径，--console-address \":9001\"则指定了Web控制台的监听地址为容器内部的9001端口。\n\n浏览器访问：http://IP:9001/minio/login，登录使用自定义账户密码admin/admin123456登录\n\n\nDocker 部署 consul#\n\n\n单节点部署#\n\n\n\n * -p 8500:8500: HTTP API 和 Web UI\n * -p 8600:8600/udp: DNS 接口\n * -v /home/docker/consul/config:/consul/config: 挂载配置目录\n * -v consul-data:/consul/data: 挂载数据目录仍用 Volume\n * -config-dir=/consul/config: 指定配置目录\n * -data-dir=/consul/data: 指定数据目录\n\nhttps://developer.hashicorp.com/consul/tutorials/archive/docker-container-agents\n#configure-and-run-a-consul-server\n\n\nconsul操作#\n\ndocker启动完整单节点consul#\n\n1. 配置acl.hcl#\n\n宿主机/home/docker/consul/config/acl.hcl\n\n\n\n2. 启动 创建卷，启动docker#\n\n\n\n3. 生成token#\n\n启动后, docker exec consul consul acl bootstrap 命令生成 Bootstrap Token（超级管理员权限）\n\n输出example:\n\n\n\n4. 创建operate.hcl#\n\n/home/docker/consul/config/admin-operate.hcl\n\n\n\n5. 使用 Bootstrap Token 创建策略#\n\n\n\n就可以使用token登录了","routePath":"/document/docker/docker快速部署容器","lang":"","toc":[{"text":"Docker 部署 Mysql","id":"docker-部署-mysql","depth":2,"charIndex":3},{"text":"Docker 部署 Mongodb","id":"docker-部署-mongodb","depth":2,"charIndex":510},{"text":"单节点部署mongo","id":"单节点部署mongo","depth":3,"charIndex":632},{"text":"Docker 部署 Minio","id":"docker-部署-minio","depth":2,"charIndex":706},{"text":"Docker 部署 consul","id":"docker-部署-consul","depth":2,"charIndex":1466},{"text":"单节点部署","id":"单节点部署","depth":3,"charIndex":1486},{"text":"consul操作","id":"consul操作","depth":3,"charIndex":1854},{"text":"docker启动完整单节点consul","id":"docker启动完整单节点consul","depth":4,"charIndex":1865}],"domain":"","frontmatter":{},"version":""},{"id":10,"title":"Git","content":"#\n\n\n常用操作#\n\n\n查看项目代码总行数#\n\n\n\n\n删除本地已合并到remote的分支#\n\n通常开发会新建个分支在本地开发，开发完成后，提交到remote并合并到master/main。\n\n然后，本地开发的分支就出现了冗余。\n\n\n\n批量清除命令：\n\n主分支main：git branch --merged origin/main | grep -vE '^(main|origin/main)$' |\nxargs git branch -d\n\n主分支master：git branch --merged origin/master| grep -vE '^(master|origin/master)$'\n| xargs git branch -d\n\n命令解析：\n\n 1. git branch --merged origin/main：列出所有已经合并到 origin/main 的本地分支。这里假设你的主分支是\n    main，并且远程跟踪分支是 origin/main。如果你的主分支是 master，那么你需要将 origin/main 替换为\n    origin/master。\n\n 2. grep -vE '^(main|origin/main)$'：过滤掉 main 和 origin/main 分支，因为我们通常不想删除这些分支。\n\n 3. xargs git branch -d：对过滤后的分支列表执行 git branch -d 命令来删除这些分支。-d\n    选项会在分支未合并时阻止删除操作，如果你想强制删除即使未合并的分支，可以使用 -D 选项代替 -d。\n\n\n克隆项目报错文件超长#\n\n\n\n经常出现在windows中，因为windows文件路径的最大长度限制通常是 260 个字符。\n\n解决:git config --system core.longpaths true 告诉 Git 允许长路径","routePath":"/document/git","lang":"","toc":[{"text":"常用操作","id":"常用操作","depth":2,"charIndex":3},{"text":"查看项目代码总行数","id":"查看项目代码总行数","depth":3,"charIndex":11},{"text":"删除本地已合并到remote的分支","id":"删除本地已合并到remote的分支","depth":3,"charIndex":26},{"text":"克隆项目报错文件超长","id":"克隆项目报错文件超长","depth":2,"charIndex":697}],"domain":"","frontmatter":{},"version":""},{"id":11,"title":"Document","content":"#","routePath":"/document/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":12,"title":"Services, Load Balancing, and Networking","content":"#","routePath":"/document/kubernetes/Concepts/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":13,"title":"","content":"","routePath":"/document/kubernetes/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":14,"title":"Ubuntu下安装软件","content":"#\n\n\n.bundle安装包#\n\n.bundle是linux中的一种可执行文件。类似Windows的.exe\n\n\n\n\nVM#\n\nvmos.us 下载\n\n\n服务器常用安装#\n\n\nMongoDB#\n\n一般直接安装在服务器上，参考\nhttps://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/#install-\nmongodb-community-edition\n\nmongodb的运行\nhttps://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/#run-mong\nodb-community-edition","routePath":"/document/linux/软件安装","lang":"","toc":[{"text":".bundle安装包","id":"bundle安装包","depth":2,"charIndex":3},{"text":"VM","id":"vm","depth":2,"charIndex":58},{"text":"服务器常用安装","id":"服务器常用安装","depth":2,"charIndex":76},{"text":"MongoDB","id":"mongodb","depth":3,"charIndex":87}],"domain":"","frontmatter":{},"version":""},{"id":15,"title":"Maven","content":"#\n\n\n基本介绍#\n\n\n作用#\n\n\n安装#\n\n安装#\n\n配置源#\n\n\n配置标签#\n\n<groupId>:com.{公司/BU }.业务线.[子业务线]，最多 4 级。\n\n<artifactId>:产品线名-模块名\n\n<version>:主版本号.次版本号.修订号 1.0.0\n\n<packaging>:指示将项目打包为什么类型的文件，idea根据packaging值，识别maven项目类型\n\n * jar:（default）普通java工程，打包后文件以.jar结尾\n\n * war: Java的web工程，打包后文件以.war结尾\n\n * pom: 不会打包，作为用来做继承的父工程\n\n<scope>: 指定依赖生效范围\n\n * compile: main目录 test目录 打包打包 [默认]\n * provided: main目录 test目录 Servlet\n * runtime: 打包运行 MySQL\n * test: test目录 junit\n\n<proerties>: 配置声明版本\n\n<dependencyManagement>: 用于父工程配置对依赖项的管理，还没有真正引入到工程中\n\n<dependencies>: 依赖项配置\n\n<dependency>: 具体依赖项\n\n完整参考：\n\n","routePath":"/document/maven","lang":"","toc":[{"text":"基本介绍","id":"基本介绍","depth":2,"charIndex":3},{"text":"作用","id":"作用","depth":3,"charIndex":11},{"text":"安装","id":"安装","depth":3,"charIndex":17},{"text":"安装","id":"安装-1","depth":4,"charIndex":22},{"text":"配置源","id":"配置源","depth":4,"charIndex":27},{"text":"配置标签","id":"配置标签","depth":2,"charIndex":34}],"domain":"","frontmatter":{},"version":""},{"id":16,"title":"Rust","content":"#\n\n\nrust语法#\n\n\n变量&常量#\n\n变量#\n\nrust的变量在默认情况下是不可变的。如果需要变量可变，需要使用关键字mut\n\n如let x = 5;可变为let mut x = 5;\n\n如果是声明了但不使用的变量，加前缀_改为_x\n\n常量#\n\nconst MAX_POINTS: u32 = 100000\n\n\n基本类型#\n\n * 数值类型：有符号整数(i8, i16, i32, i64, isize)、无符号整数(u8, u16, u32, u64, usize)、浮点数(f32,\n   f64)，有理数，复数\n * 字符串：字符串字面量，字符串切片&str\n * 布尔类型：true，false\n * 字符类型：单个Unicode字符，存储为4个字节\n * 单元类型：即(),其唯一的值也是()\n\n数值类型#\n\n整型#\n\n有符号： $-2^{n-1}$~$2^{n-1}-1$\n\n无符号：0~$2^{n}-1$\n\n如:\n\n * i8 -> $-2^7$~$2^7-1$ -> -128~127\n\n * u8 -> 0~$2^8-1$ -> 0~255\n\nisize和usize取决于计算机的CPU类型，32位CPU则为32为，64位CPU则为64位。\n\n默认为i32\n\n整型溢出 todo\n\n浮点类型#\n\n单精度f32和双精度f64\n\nNaN#\n\n特殊的类型 not a number, 数学上未定义的结果，\n\n基本运算#\n\n+ - * / %\n\n位运算#\n\n * &\n * |\n * ^\n * !\n * <<\n * >>：\n\nRange#\n\n1..5生成1到4的数字，不包含5。\n\n1..=5生成1到5的数字，包含5。\n\n常用于循环\n\n\n\n也可以是连续的字符\n\n\n\n更多数值和计算#\n\n * 有理数和复数\n * 任意大小的整数和任意精度的浮点数\n * 固定精度的十进制小数，常用于货币相关的场景\n\n可以使用num库等。\n\n字符#\n\n''包含的是字符，\"\"包含的是字符串\n\n字符''始终占4个字节的内存大小。\n\n但字符串\"\"默认utf8编码，是变长的，按具体字符集占长度。\n\nbool#\n\ntrue & false，内存大小为1个字节。\n\n单元类型#\n\n()\n\n\n所有权#\n\n&x访问x的引用\n\n*y访问y引用所指向的值\n\n\n复合类型#\n\n字符串 & 切片\n\n元组\n\n结构体\n\n数组\n\n\n模式匹配#\n\nmatch & if let\n\n\ntrait#\n\nmarker trait#\n\nSend#\n\n标记类型可以安全地跨线程转移所有权\n\ndyn （Dynamic Dispatch）#\n\n动态分发\n\n\n关键字#\n\npub#\n\n修饰符                        可见范围\npub                        对所有模块可见（公开 API）\npub(crate)                 对**当前 crate（整个包）**可见\npub(super)                 仅对直接父模块可见\npub(in path::to::module)   仅对指定路径的模块可见\n（无修饰符，默认）                  仅对当前模块可见\n\n\n[derive(xxx)]#\n\n * Debug: #[derive(Debug)]: 支持debug时，自动输出内部值。\n * \n\n\n语法例子#\n\npub trait DynStream: AsyncRead + AsyncWrite + Send + 'static {}\n\n这里表示 实现DynStream的类型必须同时实现 AsyncRead、AsyncWrite、Send 这三个 trait，并且还必须满足 'static\n生命周期约束。\n\n\n开发#\n\n\n调试#\n\neg:\n\n\n\ncargo test\n\n如果要查看test中的print，cargo test -- --nocapture","routePath":"/document/rust","lang":"","toc":[{"text":"rust语法","id":"rust语法","depth":2,"charIndex":3},{"text":"变量&常量","id":"变量常量","depth":3,"charIndex":13},{"text":"变量","id":"变量","depth":4,"charIndex":21},{"text":"常量","id":"常量","depth":4,"charIndex":120},{"text":"基本类型","id":"基本类型","depth":3,"charIndex":158},{"text":"数值类型","id":"数值类型","depth":4,"charIndex":355},{"text":"字符","id":"字符","depth":4,"charIndex":818},{"text":"bool","id":"bool","depth":4,"charIndex":894},{"text":"单元类型","id":"单元类型","depth":4,"charIndex":926},{"text":"所有权","id":"所有权","depth":3,"charIndex":938},{"text":"复合类型","id":"复合类型","depth":3,"charIndex":969},{"text":"模式匹配","id":"模式匹配","depth":3,"charIndex":1000},{"text":"trait","id":"trait","depth":3,"charIndex":1024},{"text":"marker trait","id":"marker-trait","depth":4,"charIndex":1032},{"text":"dyn （Dynamic Dispatch）","id":"dyn-dynamic-dispatch","depth":4,"charIndex":1073},{"text":"关键字","id":"关键字","depth":3,"charIndex":1105},{"text":"pub","id":"pub","depth":4,"charIndex":1111},{"text":"[derive(xxx)]","id":"derivexxx","depth":3,"charIndex":1354},{"text":"语法例子","id":"语法例子","depth":3,"charIndex":1422},{"text":"开发","id":"开发","depth":2,"charIndex":1582},{"text":"调试","id":"调试","depth":3,"charIndex":1588}],"domain":"","frontmatter":{"title":"Rust","author":"tianye","date":"2025-07-08T00:00:00.000Z","updated":"2025-07-08T18:49:21.000Z","tags":["rust"]},"version":""},{"id":17,"title":"Typescript","content":"#\n\n\nUtility Types（公共类型）#\n\n参考: https://www.typescriptlang.org/docs/handbook/utility-types.html\n\n\nPartial<Type>#\n\nConstructs a type with all properties of Type set to optional. This utility will\nreturn a type that represents all subsets of a given type.\n\n构造一个包含T中所有属性且都为可选的type。\n\n使用场景： 当需要更新T中部分参数时\n\n\nPick<Type， Keys>#\n\nConstructs a type by picking the set of properties Keys (string literal or union\nof string literals) from Type.\n\n构造一个从类型T中挑选部分指定属性组合而成的类型。\n\n\n\n\nOmit<Type>#\n\nConstructs a type by picking all properties from Type and then removing Keys\n(string literal or union of string literals). The opposite of Pick.\n\n构造一个从类型T中去掉部分指定属性组合而成的类型。与Pick相反\n\n\n\n\ntsconfig.json#\n\nhttps://json.schemastore.org/tsconfig\n\n\ncompilerOptions#\n\n指定TypeScript编译器如何编译你的项目\n\nmodule#\n\n指定编译后的模块标准, 除了下面的，还包括None, Node16, NodeNext, Preserve\n\n * CommonJS: 编译成require()、module.exports的格式\n * ESNext: 使用最新的JavaScript模块标准（即ECMAScript模块）\n * ES2015/ES6/ES2020/ES2022: 指定版本的ES\n * UMD(Universal Module Definition):\n   一种试图支持所有模块定义API的模式。它可以在AMD、CommonJS和全局变量定义之间自动切换，这使得它非常适合编写既能在浏览器环境中又能在服务器端运行\n   的库\n * AMD(Asynchronous Module Definition):\n   主要用于浏览器环境，允许模块和依赖异步加载。完全基于浏览器的应用，并且你不想用打包工具，可以使用\n * System:\n   一种动态模块加载器，可以加载各种格式的模块（包括ES模块、CommonJS和AMD），适用于开发阶段，因为它允许你以不同的模块格式混合使用代码","routePath":"/document/typescript","lang":"","toc":[{"text":"Utility Types（公共类型）","id":"utility-types公共类型","depth":2,"charIndex":3},{"text":"`Partial<Type>`","id":"partialtype","depth":3,"charIndex":-1},{"text":"`Pick<Type， Keys>`","id":"picktype-keys","depth":3,"charIndex":-1},{"text":"`Omit<Type>`","id":"omittype","depth":3,"charIndex":-1},{"text":"`tsconfig.json`","id":"tsconfigjson","depth":2,"charIndex":-1},{"text":"`compilerOptions`","id":"compileroptions","depth":3,"charIndex":-1},{"text":"`module`","id":"module","depth":4,"charIndex":-1}],"domain":"","frontmatter":{},"version":""},{"id":18,"title":"数学","content":"#\n\n\n数学概念#\n\n毕达哥拉斯定理(Pythagorean theorem / Pythagoras'\ntheorem)：即勾股定理。扩展，n维空间（歐幾里得空間）中两点间的长度为欧几里得距离","routePath":"/document/数学","lang":"","toc":[{"text":"数学概念","id":"数学概念","depth":2,"charIndex":3}],"domain":"","frontmatter":{},"version":""},{"id":19,"title":"单例模式","content":"#\n\n单例模式（Singleton Pattern），属于创建型模式。\n\n 1. 唯一性： 单例模式确保一个类在应用程序的整个生命周期中只存在一个实例。这意味着无论有多少个地方请求该类的实例，最终只会创建一个对象。\n\n 2. 全局访问点： 提供一个全局访问点（通常是一个静态方法或属性），以便从应用程序的任何部分访问这个唯一的实例。这使得可以方便地控制和限制对该实例的访问。\n\n 3. 延迟初始化（可选）： 单例模式可以支持延迟初始化，即实例的创建可以在第一次被请求时才发生，而不是在类加载时立即创建。这种实现方式被称为“懒汉式”单例。\n\n 4. 线程安全性： 在多线程环境中，单例模式的实现需要考虑线程安全问题，确保即使在多个线程同时请求实例的情况下，也只会创建一个实例。\n\n 5. 私有构造函数：\n    单例模式要求类的构造函数是私有的，防止外部代码直接创建新的实例。通常，单例类还会阻止克隆（clone()）操作和反序列化（readResolve()），\n    以进一步保证实例的唯一性。\n\n 6. 可配置性（有时）： 某些单例模式的实现允许配置是否应该创建单例，或者在什么条件下创建单例，比如在分布式系统中可能需要每个节点都有自己的实例。\n\n 7. 生命周期管理： 单例模式负责管理自身实例的生命周期，包括创建、销毁和清理资源。\n\n 8. 适用场景： 单例模式适用于那些需要在整个应用中频繁访问且每次访问都返回相同状态的对象，例如日志管理器、数据库连接池、线程池、配置管理器等。","routePath":"/document/设计模式/单例模式","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":20,"title":"","content":"This is Home!","routePath":"/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":21,"title":"TCP 粘包","content":"#\n\n\n是什么#\n\nTCP粘包（TCP Packet\nCoalescing）是指在使用TCP协议进行数据传输时，发送端连续发送的多个数据包到达接收端时可能被合并为一个较大的数据块，或者接收端从缓冲区读取数据时，无法\n准确地区分出原本分开发送的多个数据包的边界的现象。\n\n\n为什么#\n\nTCP是一个面向连接的、可靠的传输层协议，它将数据流看作无边界的字节流，而不像UDP那样保留每个数据报文的独立性。TCP协议为了提高传输效率，可能会将多个小的数\n据包聚合成一个大的数据块进行发送，或者由于网络状况、拥塞控制等因素，导致多个数据包在网络中排队等待，最终一起到达接收端。\n\n\n可能产生原因：#\n\n 1. 发送方因素：TCP协议内部的 Nagle 算法（默认的）为了减少网络中微小的数据包，可能会缓存较小的数据片段，并等到一定条件满足时再一起发送。\n 2. 接收方因素：TCP接收端有一个缓冲区，当数据包到达时会先存储在缓冲区中，如果接收应用没有及时读取数据，那么后续到达的数据包可能会与之前的数据包在缓冲区内\n    连续存放，造成接收端无法区分原始数据包的边界。\n\n图示\n\n 1. 理想情况下，接收方会按顺序依次接收msg1、msg2、msg3。\n\n\n\n 2. 但发送方为了提高效率，对消息进行了合并处理。\n\n\n\n 3. 接收方缓冲区大小有限，不知边界，无法正确处理发送来的数据。(半包)\n    \n    \n\n\n解决办法#\n\n为了解决TCP粘包问题，应用程序在设计时通常需要在应用层制定一种协议或规则来划分数据包的边界，常见的解决方案包括：\n\n * 定长消息：每个消息具有固定的长度，根据长度字段来判断消息的结束位置。\n * 分界符法：在每个消息末尾添加特定的分隔符，接收方通过查找分隔符来分离出一个个独立的消息。\n * 消息头+消息体长度法：在每个消息前添加一个包含消息长度的头部，根据头部的信息来提取完整的消息内容。\n\n简单的处理代码：\n\n","routePath":"/interview/TCP粘包","lang":"","toc":[{"text":"是什么","id":"是什么","depth":2,"charIndex":3},{"text":"为什么","id":"为什么","depth":2,"charIndex":135},{"text":"可能产生原因：","id":"可能产生原因","depth":3,"charIndex":285},{"text":"解决办法","id":"解决办法","depth":2,"charIndex":605}],"domain":"","frontmatter":{},"version":""},{"id":22,"title":"Interview","content":"#","routePath":"/interview/","lang":"","toc":[],"domain":"","frontmatter":{},"version":""},{"id":23,"title":"Markdown Extension Examples","content":"#\n\nThis page demonstrates some of the built-in markdown extensions provided by\nVitePress.\n\n\nSyntax Highlighting#\n\nVitePress provides Syntax Highlighting powered by Shiki, with additional\nfeatures like line-highlighting:\n\nInput\n\n\n\nOutput\n\n\n\n\nCustom Containers#\n\nInput\n\n\n\nOutput\n\nINFO\n\nThis is an info box.\n\nTIP\n\nThis is a tip.\n\nWARNING\n\nThis is a warning.\n\nDANGER\n\nThis is a dangerous warning.\n\nDETAILS\n\nThis is a details block. a\n\n\nMore#\n\nCheck out the documentation for the full list of markdown extensions.","routePath":"/markdown-examples","lang":"","toc":[{"text":"Syntax Highlighting","id":"syntax-highlighting","depth":2,"charIndex":91},{"text":"Custom Containers","id":"custom-containers","depth":2,"charIndex":240},{"text":"More","id":"more","depth":2,"charIndex":431}],"domain":"","frontmatter":{},"version":""},{"id":24,"title":"Rust","content":"#\n\n\nING#\n\n\nTODO#\n\n * Writing an OS in Rust 学，翻译\n\n * deno","routePath":"/rust/","lang":"","toc":[{"text":"ING","id":"ing","depth":2,"charIndex":3},{"text":"TODO","id":"todo","depth":2,"charIndex":10}],"domain":"","frontmatter":{},"version":""}]